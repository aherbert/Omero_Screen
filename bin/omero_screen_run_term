#!/usr/bin/env python3

import argparse

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Program to run Omero Screen for the screen ID."
    )
    parser.add_argument("ID", type=int)
    group = parser.add_argument_group("Omero Screen overrides")
    group.add_argument("-r", "--dir", dest="dir", help="Results directory")
    group.add_argument("-f", "--file", dest="file", help="Results summary file")
    group.add_argument(
        "-d", "--debug", dest="debug", action="store_true", help="Debug mode"
    )
    group.add_argument(
        "--gpu",
        dest="gpu",
        action="store_true",
        help="add non cuda GPU option to Cellpose",
    )

    group.add_argument("--inference", type=str, default=None, metavar="MODEL",
        help="Inference model filename.")
    group.add_argument("--gallery", type=int, default=0,
        help="Width N of for the inference galleray NxN (default: %(default)s)")
    group.add_argument("--batch", type=int, default=16,
        help="Classification batch size (default: %(default)s)")
    args = parser.parse_args()

    # Create overrides
    opt = {}
    if args.dir is not None:
        opt["DEFAULT_DEST_DIR"] = args.dir
    if args.file is not None:
        opt["DEFAULT_SUMMARY_FILE"] = args.file
    if args.debug:
        opt["DEBUG"] = True
    if args.gpu:
        opt["GPU"] = "GPU"
    if args.inference:
        opt["INFERENCE_MODEL"] = args.inference
    if args.gallery:
        opt["INFERENCE_GALLERY_WIDTH"] = args.gallery
    if args.batch:
        opt["INFERENCE_BATCH_SIZE"] = args.batch

    # lazy import to speed up parsing errors
    import omero_screen.main

    omero_screen.main.main(args.ID, options=opt)
